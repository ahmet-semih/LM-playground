{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e849ab7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "\n",
    "from safetensors import torch as sftorch\n",
    "\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"./llama_architecture\")\n",
    "\n",
    "from model_trnsfmrs import LlamaForCausalLM\n",
    "from config import LlamaConfig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e57d3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"mps\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e9a01da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    \"\"\"Count the number of parameters in a model\"\"\"\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    return total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d873cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"aliarda/turkish-news-32k-tokenizer\")\n",
    "model_path = hf_hub_download(repo_id=\"aliarda/llama-50M-latest\", filename=\"model.safetensors\")\n",
    "state_dict = sftorch.load_file(model_path, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d111ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52177152\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32768, 256)\n",
       "    (layers): ModuleList(\n",
       "      (0-19): 20 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (k_proj): Linear(in_features=256, out_features=128, bias=False)\n",
       "          (v_proj): Linear(in_features=256, out_features=128, bias=False)\n",
       "          (o_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=256, out_features=2048, bias=False)\n",
       "          (up_proj): Linear(in_features=256, out_features=2048, bias=False)\n",
       "          (down_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=256, out_features=32768, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama_config = LlamaConfig(\n",
    "    vocab_size=32768,\n",
    "    emb_dim=256,\n",
    "    context_length=256,\n",
    "    n_heads=128,\n",
    "    n_layers=20,\n",
    "    n_kv_groups=64,\n",
    "    hidden_dim=2048,\n",
    ")\n",
    "\n",
    "llama_model = LlamaForCausalLM(llama_config, tokenizer)\n",
    "print(count_parameters(llama_model))\n",
    "llama_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6db17ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_model.load_state_dict(state_dict)\n",
    "llama_model.to(device)\n",
    "llama_model.device = device\n",
    "llama_model.context_len = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "869a2f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'merhaba sayın okuyucularım, siz bu yazıyı yazdım ve yazdım.\\n[old_news_related_template title=\"Türkiye\\'de koronavirüs vakaları artmayadevamediyor\"desc=\"Türkiye\\'de koronavirüs vakalarının artmasıüzerine SağlıkBakanı Fahrettin Koca\\'nın açıkladığı koronavirüs vakasayısı merakediliyor.Pekiama bugünkü vakasayısı kaç oldu? 18 Temmuz 2021 bugünkü vakasayısı kaç oldu? 18 Temmuz 2021 koronavirüs tablosu\\nSondakika gündem haberinegöre SağlıkBakanı Fahrettin Koca\\'nın açıkladığı koronavirüs tablosu merakediliyor.Pekiama bugünkü vakasayısı kaç oldu? 18 Temmuz 2021 koronavirüs tablosu merakediliyor.Sağlık Bakanı Fahrettin Koca koronavirüsle mücadelede sondurum ne? sorusunun yanıtını araştırıyor.Pekiama bugünkü vakasayısı kaç oldu? 20 Ocak 2021 koronavirüs tablosu…\\nİLTİFEKSİYONLARINDA SON DURUM NE: Koronavirüs vakasayısı ve tablosu merakediliyor.Sağlık Bakanı Fahrettin Koca koronavirüsle mücadelede alınan önlemler konusunda vatandaşlara uyarılarda bulundu.Pekiama bugünkü vakasayısı kaç oldu? 20 Ocak 2021 koronavirüs tablosu | Yüzde 50 hasta var\\nTürkiye\\'de son24saatte 34 bin 981 yeni vaka tespitedildi, 5bin 943 kişinin testi pozitif çıktı, 188kişi yaşamınıyitirdi.\\nSondakika... CumhurbaşkanıErdoğan\\'dan taziye mesajı!\\nCumhurbaşkanıErdoğan, koronavirüsle mücadelede yeni dönem başlıyor! Günlük burçyorumları bugün neler? 20 Ocak 2021 Salı gününün günlük burçyorumları...Kutsal hayatınızda sondakika gelişmeleri!\\n20 Şubat 2021 Salı Günlük BurçYorumlarında Koç burcunu bugün'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama_model.generate(\"merhaba sayın okuyucular\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
